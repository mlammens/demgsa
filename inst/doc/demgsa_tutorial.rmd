---
title: "Global Sensitivity Analysis of Demographic Models Using demgsa"
author: "Matthew E. Aiello-Lammens"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{demgsa Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

# Overview

This tutorial goes through how to use the `demgsa` package to perform a global
sensitivity analysis (GSA) of a demographic model constructed using the 
[RAMAS GIS](http://ramas.com/software.htm) Software. `demgsa` includes 
functions to make easier each major step of a GSA:

1. Creation of new demographic models parameterized with random sets of values,
which represent the uncertainty and/or stochasticity inherent in each parameter.
2. Creation of scripts to batch run RAMAS GIS models.
3. Reading and collating of model inputs and results for further analysis.

Using these results, we can examining the uncertainty of the input parameters 
and the variability of various end-point metrics (e.g., Quasi-extinction 
measures and Expected Minimum Abundance values), and assess the relative 
importance of this uncertainty.

In addition, in this tutorial, we demonstrate how to use paired simulations to
carry out impact assessments. Using this method it is possible to evaluate the
affect of environmental impacts (e.g., global climate change) or changes to 
model structure (e.g., changes to density dependence assumptions) on model
outcomes.

## Parameters allowed to vary in version 0.1.0 of demgsa

The following parameters are allowed to vary in the current implementation
of `demgsa`.

* Each element of the stage/age matrix (i.e. survival and fecundity)
* Each element of the stage/age standard deviation matrix 
(i.e. variability in survival and fecundity)
* Dispersal Rates
  * Each element of the dispersal-distance function (all varied using **One** 
  random variable)
  * Each element of the dispersal matrix, either each independently or all 
  dependently (user determined)
  * Discretely between DCH scenarios (includes discrete selection of Dispersal 
  Matrix as well)
* Inter-population Correlation
  * Each element of the correlation-distance function (all varied using **One** 
  random variable)
  * Each element of the correlation matrix (all varied using **One** random 
  variable)
* Stage Initial Abundance Distribution Values
  * User can select use of Stable Age Distribution, as determined by the matrix 
  elements
  * User can allow stage initial abundance distribution values to vary - actual 
  initial abundance 
  values are varied else where in the script
* Population Initial Abundance - All populations varied using **One** random 
value
* Population specific Rmax - All populations varied using **One** random value
* Population Carrying Capacity
  * KCH files chosen discretely between scenarios using **One** random value

# Initial set-up

## Install the `demgsa` package

Currently the `demgsa` package is available via [github](https://github.com/). 
The easiest way to install this package is to use the 
[devtools](https://github.com/hadley/devtools) package.


```{r}
## Check for devtools. Install if not already installed.
if( !( "devtools" %in% installed.packages() ) ){
  install.packages( "devtools" ) 
}

## Load devtools package
library( devtools )

## Check for demgsa. Install if not already installed
if( !( "demgsa" %in% installed.packages() ) ){
  devtools::install_github( "mlammens/demgsa" ) 
}

## Load demgsa package
library( demgsa )
```

```{r, echo=FALSE}
data( snpl_nocc_results )
data( snpl_2m_results )
```


## demgsa Functions

If you successfully carried out the above steps, then you can now use any of
the `demgsa` functions. While a simple sensitivity
analysis will require the user to call only one of these functions 
(`sensitivity`), the other functions
can also be used on their own to:

* Determine which Metapop version was used to create a particular *.mp file
* Read a *.mp file and store it's contents in a list structure
* Read a *.ptc file
* Write a new *.mp file, in the event that you adjusted a file you read in

# Running a Sensitivity Analysis

## Metapop File Preparation

To run a GSA, the user supplies at least two *.mp files, 
one of which has all of the lowest estimates for any uncertain parameters 
and the other which has all of the highest estimates for any uncertain 
parameters.  Note that this is different than  ‘best case’ and ‘worst case’ 
scenario *.mp files.  Some high values for parameters may be 
associated with a ‘worst case’ scenario (e.g., correlation 
structure among populations), which would include low values of 
other parameters (e.g., survival or fecundity). The 
[demgsa GitHub repository](https://github.com/mlammens/demgsa) contains all of 
the files need to work through this tutorial, including sample *mp files, in 
the `inst/extdata` directory. 

## Modifying the sens_config.txt file

Once the `demgsa` package is installed on loaded into your R workspace, you are
ready to run a GSA on your demographic model. The next step is to modify the
configuration file to match your specific demographic model parameters. A
template file can be found in the `demgsa` GitHub repository 
[here](https://github.com/mlammens/demgsa/blob/master/inst/extdata/sens_config.txt).
Each of the parameters that needs to be set is described in this sens_config.txt 
file. 
This is a template file that can be copied and modified to setup
the configurations of individual sensitivity runs.  Step through this 
file and read all of the material in it.  
The template is parameterized to run the sample model examined in this 
tutorial, which is a demographic model of the Florida Snowy Plover[^1]. During
these first steps, we carry out a GSA on a model with no effect of sea-level
rise.

[^1]: Aiello-Lammens et al. 2011. The impact of sea‐level rise on Snowy Plovers in Florida: integrating geomorphological, habitat, and metapopulation models. Global Change Biology 17(12): 3644-3654


### Special cases for varying Carrying Capacity and Migration (Dispersal) scenarios

More than two *.mp files can be used to test uncertainty in changes through 
time of carrying capacity 
or dispersal parameters. In RAMAS Metapop, these changes are implemented 
via change files, or *.?CH files.  For example, for the Snow Plover 
example used here, we incorporated changes to 
population carrying capacity resulting from forecasted sea-level rise, 
using RAMAS GIS to create a spatially dynamic demographic model in which 
population carrying capacity decreases over the course of the simulation. 
The population carrying capacities for each patch is stored in *.KCH 
files (one per patch). We generated three
carrying capacity change scenarios (Low, Medium, and High carrying capacities). 
In carrying out a sensitivity analysis, we choose one of these 
three scenarios at random to accompany the other randomly 
chosen parameter values.  A similar method can be implemented to vary 
Migration (Dispersal) scenarios, which may change through time in a 
dynamic spatial model as well, as populations change in size 
and distance from each other, or shift in space. 

## Step 1. Creation of new demographic models parameterized with random sets of values

The first step of this GSA is to create new *mp files 
parameterized with random sets of values,
which represent the uncertainty and/or stochasticity inherent in each parameter.
This is done using the `sensitivity` function. The argument to the
`sensitivity` function is the sens_config file. For the no climate change
(i.e., no SLR) scenario, the associated file is sens\_config\_nocc.txt.

To complete this tutorial on your own system, you should copy the files stored
in the `inst/extdata` directory into a new directory, then set this new
directory as the working directory (using `setwd()`).
To determine where the `inst/extdata` folder is, you can use the following
command:

```{r}
system.file("extdata", package = "demgsa")
```

Once you've copied these files into a new directory, set that new directory
as the working directory, and carry on with the tutorial.

```{r, eval=FALSE}
## Set working directory -- change this line according to where you placed
## these files!
setwd( "inst/extdata/" )

## Call the sensitivity function using the sens_config file for nocc
sensitivity( "sens_config_nocc.txt" )
```

A successful run of `sensitivity` should result in 10 new *.mp files
(the number of replicates set in our example sens\_config file). Note that
the new *.mp files can be created in any directory the user desires, but if 
the simulations require any change-through-time files (e.g., KCH or DCH), 
then those files most be in the same directory as the *.mp files. For this 
reason, in this example we save the new *.mp files in the `inst/extdata` 
directory.

In addition to the new *.mp files, if `use.rv.file` was set to `FALSE` in the 
sens_config file, a CSV file of the randomizer values is created. 
In this example, the resulting file 
is named `snpl_rv.csv`. 

## Step 2. Batch run new *.mp files

Two other files that are created by `sensitivity` are a 
Windows formatted batch script (`*.BAT`)
and a \*nix formatted batch script (`*.sh`). 
These two files help the user to batch run the 
new *.mp files.

### Using the Windows formated batch script

The Windows formatted batch script uses a "helper" batch script names 
`RunMP.BAT`. This file includes the path to the RAMAS GIS Metapopulation 
module on your system. Open this file, and adjust the path accordingly.
After this is done, the files can be run by simply double-clicking on the 
`*.BAT` file created by `sensitivity`.

### Using the *nix formated batch script

Running RAMAS GIS modules on *nix systems requires
[wine](https://www.winehq.org/). Once RAMAS is properly running on your
*nix system, then the best way to run the `sensitivity` created shell script
is to first create a symbolic link to the Metapopulation module in the directory
the *.mp and *.sh files are in. This is best done using Terminal, from
within this directory. Once in that directory, execute the following command,
substituting in the correct path for your system:

```
ln -s /Users/mlammens/Dropbox/RAMASGIS/Metapop.exe .
```

Now the *.sh file can be executed using the following command, replacing
the *.sh file name as appropriate:

```{}
/bin/bash snpl_batch_nocc0.sh
```

## Step 3. Reading and collating model results

After the new *.mp files have been run, we want to extract the simulation
results and input parameters used. We do this using the `mp.mult.results` 
function, which is a wrapper for the `mp.results` function. The latter extracts
results for a single *.mp file.

```{r eval=FALSE}
## Get a list of mp files to extract results from
mp_list <- list.files( pattern = "snpl_nocc.*mp", full.names = TRUE )

## Call mp.mult.results
mp.mult.results( mp.file.list = mp_list, out.csv = "snpl_nocc_results.csv", spatial = TRUE )
```

Now we can read in the resulting CSV file.

```{r, eval=FALSE}
## Read in the resulting CSV file
snpl_nocc_results <- read.csv( "snpl_nocc_results.csv" )
```

Begin by looking at a brief summary of these data.

```{r}
summary( snpl_nocc_results )
```

Let us look at a simple plot of growth rate versus expected minimum abundance

```{r}
plot( data = snpl_nocc_results, exp.min.n ~ GrowthRt )
```

As we would expect, as growth rate increases, so does expected minimum
abundance.

# Running a second sensitivity analysis on a simulation considering 2m SLR

We will now go through how to carry out paired sensitivity analysis, taking
advantage of the saved randomizer CSV file. We have created three additional
*.mp files that are identical to the three used above **except** that these 
incorporate the effects of changes in rising sea level (2m sea-level rise).
The overall affect of 2m SLR is to decrease the carrying capacity of each of 
the sub-populations in the metapopulation over the course of the simulation
period (i.e., 2010 - 2100).

The most important step in this process is to set `use.rv.file = TRUE` in the
sens_config file associated with the 2m SLR scenario **AND** to set the 
`rv.file` to the appropriate file (and path if necessary). Once this is 
done, then running the GSA for the 2m SLR scenario is identical to the NoCC 
scenario.

## Step 1. Create new models

```{r, eval=FALSE}
## Call the sensitivity function using the sens_config file for 2m slr
sensitivity( "sens_config_2m.txt" )
```

## Step 2. Batch run the models

```{}
/bin/bash snpl_batch_2m0.sh
```

## Step 3. Extract the results

```{r eval=FALSE}
## Get a list of mp files to extract results from
mp_list_2m <- list.files( pattern = "snpl_2m.*mp", full.names = TRUE )

## Call mp.mult.results
mp.mult.results( mp.file.list = mp_list_2m, out.csv = "snpl_2m_results.csv", spatial = TRUE )
```

Now we read in the CSV results file for the 2m SLR scenario.

```{r, eval=FALSE}
## Read in the resulting CSV file
snpl_2m_results <- read.csv( "snpl_2m_results.csv" )
```

## Compare NoCC and 2m SLR results

First, let's verify that (at least some of) 
the non-SLR associate parameters are identical

```{r}
all( snpl_nocc_results$GrowthRt == snpl_2m_results$GrowthRt )
all( snpl_nocc_results$stdev.avg == snpl_2m_results$stdev.avg )
```

Next let's compare the expected minimum abundance values from the two
sets of models. The red line is the 1:1 line. We see very clearly that 
EMA is lower for the 2m SLR scenario than it is for the NoCC scenario.
Because all input parameters, other than the carrying capacity change
through time (which is due to the 2m SLR) are identical, this decrease is
directly attributable to the effects of the forecasted impact of rising
sea levels.

```{r}
plot( x = snpl_nocc_results$exp.min.n, y = snpl_2m_results$exp.min.n,
      xlab = "EMA for NoCC scenario", ylab = "EMA for 2m SLR scenario" )
abline( a = 0, b = 1, col="red" )
```


# Modifying demgsa functions

We encourage you to fork the `demgsa` package on GitHub and modify the 
functions as needed for your analyses. If you make a general change,
please feel free to submit it as a Pull Request.

## Why modify?

The most likely scripts that you may want to modify are those pertaining 
to results extraction. Other potential reasons for modification include:

* Account for parameters not currently varied
    * User defined Density Dependence values
    * Other values in the 'Population Specific' parameters
    * Management actions
* Incorporate a user defined randomization method (i.e. something other than
urand or LHS)
* Use the package for other PVA programs
    * To modify the package for use with another PVA program, you will need to write functions for reading input and writing output files for that program, replacing the current functions `mp.read.r` and `mp.write.r`, respectively. Your input function would read a file to fill the `mp.file` data structure defined in `mp.read.r`. If the PVA program you are using does not include certain parameters specified in this structure, your input function could simply set the same default value for both upper and lower bounds (thereby removing this parameter from the sensitivity analysis). If the PVA program you are using includes parameters that are not specified in the data structure of this package, then you would either have to add those parameters to the sensitivity analysis yourself or do not use them in the GSA. To add them, an easy approach would be to copy the code for an existing parameter and modify. (Of course, in either case, the output function would have to write them). 
    * An alternative approach would be to write separate functions for converting the RAMAS input file (MP) format into the format for your PVA program (and vice versa). In this case, you would have to use default values for any parameter that is not common to both programs (in other words, you would not be able analyze sensitivity to parameters included in your PVA program but not in RAMAS).


